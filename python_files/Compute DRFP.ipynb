{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34004dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from drfp import DrfpEncoder\n",
    "from functools import partial\n",
    "from typing import Iterable\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing\n",
    "from typing import Tuple\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f2bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"amidation_carboxylicAcid_primaryAmine_ECFP_2048.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1875e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data[data['Yield']<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed27362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\george.hodgin\\AppData\\Local\\Temp\\ipykernel_19432\\1032285679.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['Reactants'] = data_1['SMILES'].str.split('>', expand=True)[0]\n",
      "C:\\Users\\george.hodgin\\AppData\\Local\\Temp\\ipykernel_19432\\1032285679.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['Agents'] = data_1['SMILES'].str.split('>', expand=True)[1]\n",
      "C:\\Users\\george.hodgin\\AppData\\Local\\Temp\\ipykernel_19432\\1032285679.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['Products'] = data_1['SMILES'].str.split('>', expand=True)[2]\n",
      "C:\\Users\\george.hodgin\\AppData\\Local\\Temp\\ipykernel_19432\\1032285679.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['Reactants+Agents'] = data_1['Reactants'] + \".\" + data_1[\"Agents\"]\n",
      "C:\\Users\\george.hodgin\\AppData\\Local\\Temp\\ipykernel_19432\\1032285679.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['Reaction'] = data_1['Reactants+Agents'] + \">>\" + data_1[\"Products\"]\n"
     ]
    }
   ],
   "source": [
    "# Add the reagents to the reactants and rejoin with >> \n",
    "data_1['Reactants'] = data_1['SMILES'].str.split('>', expand=True)[0]\n",
    "data_1['Agents'] = data_1['SMILES'].str.split('>', expand=True)[1]\n",
    "data_1['Products'] = data_1['SMILES'].str.split('>', expand=True)[2]\n",
    "data_1['Reactants+Agents'] = data_1['Reactants'] + \".\" + data_1[\"Agents\"]\n",
    "data_1['Reaction'] = data_1['Reactants+Agents'] + \">>\" + data_1[\"Products\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9140e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(smiles: Iterable, length: int = 2048, radius: int = 3) -> np.ndarray: \n",
    "    return DrfpEncoder.encode(\n",
    "        smiles,\n",
    "        n_folded_length=length,\n",
    "        radius=radius,\n",
    "        rings=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def encode_dataset(smiles: Iterable, length: int, radius: int) -> np.ndarray:\n",
    "    \"\"\"Encode the reaction SMILES to drfp\"\"\"\n",
    "\n",
    "    cpu_count = (\n",
    "        multiprocessing.cpu_count()\n",
    "    )  # Data gets too big for piping when splitting less in python < 2.8\n",
    "\n",
    "    # Split reaction SMILES for multiprocessing\n",
    "    k, m = divmod(len(smiles), cpu_count)\n",
    "    smiles_chunks = (\n",
    "        smiles[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)]\n",
    "        for i in range(cpu_count)\n",
    "    )\n",
    "\n",
    "    # Run the fingerprint generation in parallel\n",
    "    results = []\n",
    "    with multiprocessing.Pool(cpu_count) as p:\n",
    "        results = p.map(partial(encode, length=length, radius=radius), smiles_chunks)\n",
    "\n",
    "    return np.array([item for s in results for item in s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "drfps = encode_dataset(data_1['Reaction'], length=2048, radius=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7670eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, Random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86866ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_num = 1\n",
    "for train_index, test_index in kf.split(drfps):\n",
    "    \n",
    "    # Make splits for drfp and ecfp training sets\n",
    "    X_train_drfp, X_test_drfp = drfps[train_index], drfps[test_index]\n",
    "    X_train_ecfp, X_test_ecfp = data_1.iloc[train_index,:-3], data_1.iloc[test_index,:-3]\n",
    "    y_train, y_test = data_1.loc['Yield'][train_index], data_1.loc['Yield'][test_index]\n",
    "    \n",
    "    # Group together the X_y and dump into pickle files\n",
    "    with open(\"CV{}_2048_3_DRFP_train.pkl\".format(CV_num), \"wb+\") as f:\n",
    "        pickle.dump((X_train_drfp, y_train), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"CV{}_2048_3_ECFP_train.pkl\".format(CV_num), \"wb+\") as f:\n",
    "        pickle.dump((X_train_ecfp, y_train), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"CV{}_2048_3_DRFP_test.pkl\".format(CV_num), \"wb+\") as f:\n",
    "        pickle.dump((X_test_drfp, y_test), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"CV{}_2048_3_ECFP_test.pkl\".format(CV_num), \"wb+\") as f:\n",
    "        pickle.dump((X_test_ecfp, y_test), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    CV_num +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data( \n",
    "    path_train: str,\n",
    "    path_test: str,\n",
    "    valid_frac: str = 0.1,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \n",
    "    \n",
    "    X_train, y_train= pickle.load(\n",
    "        open(\n",
    "            path_train,\n",
    "            \"rb\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    subset_indices = np.random.choice(\n",
    "        np.arange(len(X_train)), int(1.0 * len(X_train)), replace=False\n",
    "    )\n",
    "    X_train = X_train[subset_indices]\n",
    "    y_train = y_train[subset_indices]\n",
    "\n",
    "    X_test, y_test = pickle.load(\n",
    "        open(\n",
    "            path_test,\n",
    "            \"rb\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    valid_indices = np.random.choice(\n",
    "        np.arange(len(X_train)), int(valid_frac * len(X_train)), replace=False\n",
    "    )\n",
    "    X_valid = X_train[valid_indices]\n",
    "    y_valid = y_train[valid_indices]\n",
    "\n",
    "    train_indices = list(set(range(len(X_train))) - set(valid_indices))\n",
    "    X_train = X_train[train_indices]\n",
    "    y_train = y_train[train_indices]\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a031f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results( \n",
    "    set_name: str,\n",
    "    split_id: str,\n",
    "    ground_truth: np.ndarray,\n",
    "    prediction: np.ndarray,\n",
    ") -> None:\n",
    "    with open(f\"{set_name}_{split_id}.csv\", \"w+\") as f:\n",
    "        for gt, pred in zip(ground_truth, prediction):\n",
    "            f.write(f\"{set_name},{split_id},{gt},{pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c63b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define % within certain range \n",
    "def within_range(list1, list2, range2):\n",
    "    x=0\n",
    "    for i in range(len(list2)):\n",
    "        if (list1[i]-range2)<= list2[i] <= (list1[i]+range2): \n",
    "            x+=1\n",
    "    return((float(x)/(len(list2)))*100)\n",
    "\n",
    "# Define RMSE\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_uspto(train, test): \n",
    "    \n",
    "\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = load_data(\n",
    "        train,\n",
    "        test,\n",
    "        valid_frac=0.1)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=999999,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=12,\n",
    "        min_child_weight=6,\n",
    "        colsample_bytree=0.6,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit)\n",
    "    y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "    #save_results(\"uspto\", \"AcidAnhydrideP\", y_test, y_pred)\n",
    "    \n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    RMSE = rmse(y_test, y_pred)\n",
    "    within_10 = within_range(y_test, y_pred, 10)\n",
    "    within_5 = within_range(y_test, y_pred, 5)\n",
    "    \n",
    "    #save_metrics(\"uspto\", \"AcidAnhydrideP\", r_squared,\n",
    "     #            within_10, within_5, rmse)\n",
    "                 \n",
    "    \n",
    "    print(r_squared)\n",
    "    print(RMSE)\n",
    "    print(within_10)\n",
    "    print(within_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd060f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    predict_uspto(\"CV{}_2048_3_DRFP_train.pkl\".format(i), \"CV{}_2048_3_DRFP_test.pkl\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield",
   "language": "python",
   "name": "yield"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
